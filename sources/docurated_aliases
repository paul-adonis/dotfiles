# ============ Docurated Aliases =============
DOC_HOME='/Users/sampaul/Development/Docurated'
alias doc="cd $DOC_HOME"


# ===== JIRA ZSH Plugin / URLs ========
JIRA_URL='https://docurated.atlassian.net'
GITHUB_URL='https://github.com/Docurated'
JENKINS_URL='https://jenkins.service.consul'
HANGOUTS_URL='https://hangouts.google.com/hangouts'


# ===== GOOGLE HANGOUTS ========
openHangout() { open "$HANGOUTS_URL/_/docurated.com/$1?authuser=$2" }
alias relho='openHangout relevance sam@docurated.com'
alias relno='open "https://docs.google.com/a/docurated.com/document/d/1ktuCdngDhUZxfd5-uND9jC23_l9SzQiCkLMC2RU0zzg/edit?usp=sharing"'


# ===== GIT REPOS ========
alias docweb="cd $DOC_HOME/website/rails"
alias docutil="cd $DOC_HOME/utilities"
alias doccli="cd $DOC_HOME/clients"
alias docserv="cd $DOC_HOME/services"
alias docevents="cd $DOC_HOME/events"
alias docact="cd $DOC_HOME/activity"

alias hubc='open $GITHUB_URL/clients'
alias hubw='open $GITHUB_URL/website'
alias hubu='open $GITHUB_URL/utilities'
alias hubs='open $GITHUB_URL/services'
alias hube='open $GITHUB_URL/events'
alias huba='open $GITHUB_URL/activity'

searchgit() { open "https://github.com/Docurated/$1/search?utf8=âœ“&q=$2" }
alias hubcs='searchgit clients'
alias hubws='searchgit website'
alias hubus='searchgit utilities'
alias hubss='searchgit services'
alias hubes='searchgit events'
alias hubas='searchgit activity'


# ===== JENKINS ========
alias jenk='open $JENKINS_URL/'
alias jenkc='open $JENKINS_URL/job/Client%20Build/'
alias jenks='open $JENKINS_URL/job/BuildTestDeployWebStage/'
alias jenkw='open $JENKINS_URL/job/BuildTestDeployWebMaster/'
alias jenke='open $JENKINS_URL/job/Events%20Build/'
alias jenka='open $JENKINS_URL/job/Activity/'


# ===== CONSUL ========
alias conpget='consul kv get -http-addr=consul.service.consul:8500 -datacenter=us-east-1-production'
alias conpput='consul kv put -token=$CONSUL_TOKEN -http-addr=consul.service.consul:8500 -datacenter=us-east-1-production'
alias condget='consul kv get -http-addr=consul.service.consul:8500 -datacenter=us-east-1-demo'
alias condput='consul kv put -token=$CONSUL_TOKEN -http-addr=consul.service.consul:8500 -datacenter=us-east-1-demo'
alias conpgetana='conpget repos/analytics/current_release'
alias condgetana='condget repos/analytics/current_release'
alias conpputana='conpput repos/analytics/current_release'
alias condputana='condput repos/analytics/current_release'


# ===== AIRFLOW ========
alias airw='airflow webserver -D &'
alias airwq='pkill -f "airflow webserver"'
alias airwr='airwq && airw'
alias airc='airflow clear'
alias airb='airflow backfill -s `date +%Y-%m-%d`'
air_cb() {
    airc $1
    airb $1
}
alias aircb='air_cb'
alias airl='airflow list_dags'

# ===== SPARK ========
alias emr='aws emr list-clusters --active --query "Clusters[*].{Name:Name,ID:Id,State:Status.State,Info:Status.StateChangeReason.Message}"'

SPARK_KEY_PAIR='$HOME/.ssh/sams-other-key-pair.pem'
ssh_spark() {
    # printf "Using cluster DNS: %s\n" "${SPARK_PROD_CLUSTER_DNS:?You must set SPARK_PROD_CLUSTER_DNS}"
    ssh -i $1 -L 8087:$2:18080 -L 8086:$2:8088 hadoop@$2
}
alias cpspark='ssh_spark ~/.ssh/sams-other-key-pair.pem $SPARK_PROD_CLUSTER_DNS'
alias cdspark='ssh_spark ~/.ssh/sams-other-key-pair.pem $SPARK_DEMO_CLUSTER_DNS'

add_spark_step() {
    printf "Using cluster ID: %s\n" "${SPARK_PROD_CLUSTER_ID:?You must set SPARK_PROD_CLUSTER_ID}"
    aws emr add-steps --cluster-id $1 --steps "Type=spark,Name='$3',Args=[--deploy-mode,cluster,--master,yarn,--conf,spark.executorEnv.ENV=production,--conf,spark.yarn.appMasterEnv.ENV=production,--conf,spark.speculation=true,$2]"
}
alias spspark='add_spark_step $SPARK_PROD_CLUSTER_ID s3://docurated-production-analytics/main.py'
alias sdspark='add_spark_step $SPARK_DEMO_CLUSTER_ID s3://docurated-demo-analytics/main.py'
set_spark_env_var() {
    export $1=$2
}
alias sparkpc='set_spark_env_var SPARK_PROD_CLUSTER_ID'
alias sparkdc='set_spark_env_var SPARK_DEMO_CLUSTER_ID'
alias sparkpd='set_spark_env_var SPARK_PROD_CLUSTER_DNS'
alias sparkdd='set_spark_env_var SPARK_DEMO_CLUSTER_DNS'

cp_to_spark_s3() {
    aws s3 cp $2 s3://docurated-$1-analytics/$2
}
alias s3sparkpcp='cp_to_spark_s3 production'
alias s3sparkdcp='cp_to_spark_s3 demo'


# ===== SSH ========
sshconnect() { ssh $1.$2.$3 }

alias cdweb='sshconnect demo web'
alias cdapi='sshconnect demo api'
alias cdrapp='sshconnect demo railsapp'
alias cdev='sshconnect demo events'
alias cdcass='sshconnect demo cassandra'
# alias cdact='sshconnect demo activity'

alias cpweb='sshconnect production web'
alias cpapi='sshconnect production api'
alias cprapp_old='sshconnect production railsapp'
alias cpev='sshconnect production events'
alias cpcass='sshconnect production cassandra'
alias cprapp='docutil && $DOC_HOME/utilities/bin/ssh-first production resque'

ENVS=('DEMO' 'PROD' 'BIO')
HOST_TYPES=('MAIN' 'ACT' 'ANA' 'AIR')
SERVICES=('PG' 'RESQ')

MAIN_PG_PORT_DEMO=5433
MAIN_PG_PORT_PROD=5434
MAIN_PG_PORT_BIO=5435

ACT_PG_PORT_DEMO=5436
ACT_PG_PORT_PROD=5437
ACT_PG_PORT_BIO=5438

ACT_RESQ_PORT_DEMO=8286
ACT_RESQ_PORT_PROD=8287
ACT_RESQ_PORT_BIO=8288

ACT_PG_HOST_DEMO='activity-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'
ACT_PG_HOST_PROD='activity-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'
ACT_PG_HOST_BIO='activity-biomarin.cr9ikdrfc2gy.us-west-2.rds.amazonaws.com'

ANA_PG_PORT_DEMO=5439
ANA_PG_PORT_PROD=5440
ANA_PG_PORT_BIO=5441

ANA_PG_HOST_DEMO='analytics-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'
ANA_PG_HOST_PROD='analytics-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'
ANA_PG_HOST_BIO='analytics-biomarin.cr9ikdrfc2gy.us-west-2.rds.amazonaws.com'

AIR_PG_PORT_DEMO=5442
AIR_PG_PORT_PROD=5443

AIR_PG_HOST_DEMO='airflow-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'
AIR_PG_HOST_PROD='airflow-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com'

REDIS_PORT_DEMO=6380

tunnel_ssh() {
    ssh -nNT -L $1 ${2}:${3}:5432
}
tunnel_ports() {
    str=""
    for e in $ENVS; do
        for h in $HOST_TYPES; do
            port="${h}_PG_PORT_${e}"
            post="${h}_PG_HOST_${e}"
            echo port: ${(P)port}
            echo host: ${(P)host}
            str+=${(P)port}
            # echo port: ${!port}
        done
    done
    echo $str
}

# ssh remote <user@hostname> <local port>:<host>:<port>
tunnel_port() {
    ssh -nNT $1 -L ${2}:${3}:${4}
}
tunnel_demo() {
    tunnel_port demo.postgres.0 $MAIN_PG_PORT_DEMO localhost 5432 &
    tunnel_port demo.activity.0 $ACT_PG_PORT_DEMO $ACT_PG_HOST_DEMO 5432 &
    tunnel_port demo.activity.0 $ACT_RESQ_PORT_DEMO localhost 8282 &
    tunnel_port demo.analytics.0 $ANA_PG_PORT_DEMO $ANA_PG_HOST_DEMO 5432 &
    tunnel_port demo.analytics.0 $AIR_PG_PORT_DEMO $AIR_PG_HOST_DEMO 5432 &
    tunnel_port demo.analytics.0 $REDIS_PORT_DEMO main.redis.service.consul 6379 &
}
alias kill_tunnel_demo="pkill -f 'nNT demo'"
tunnel_prod() {
    tunnel_port production.postgres.0 $MAIN_PG_PORT_PROD localhost 5432 &
    tunnel_port production.activity.0 $ACT_PG_PORT_PROD $ACT_PG_HOST_PROD 5432 &
    tunnel_port production.activity.0 $ACT_RESQ_PORT_PROD localhost 8282 &
    tunnel_port production.analytics.0 $ANA_PG_PORT_PROD $ANA_PG_HOST_PROD 5432 &
    tunnel_port production.analytics.0 $AIR_PG_PORT_PROD $AIR_PG_HOST_PROD 5432 &
}
alias kill_tunnel_prod="pkill -f 'nNT prod'"

alias cdpost='connect_ssh demo.postgres.0 $MAIN_PG_PORT_DEMO localhost'
alias cppost='connect_ssh production.postgres.0 $MAIN_PG_PORT_PROD localhost'
alias cbpost='connect_ssh biomarin.postgres.0 $MAIN_PG_PORT_BIO localhost'

alias cdact='ssh demo.activity.0 -L 8286:localhost:8282 -L 5436:activity-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432'
alias cpact='ssh production.activity.0 -L 8287:localhost:8282 -L 5437:activity-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432'
alias cbact='ssh biomarin.activity.0 -L 8288:localhost:8282 -L 5438:activity-biomarin.cr9ikdrfc2gy.us-west-2.rds.amazonaws.com:5432'

# alias cdana='ssh demo.analytics.0 -L 5439:analytics-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432 -L 5442:airflow-demo.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432'
# alias cpana='ssh production.analytics.0 -L 5440:analytics-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432 -L 5443:airflow-production.cpk5zbekyq7f.us-east-1.rds.amazonaws.com:5432'
# alias cbana='ssh biomarin.analytics.0 -L 5441:analytics-biomarin.cr9ikdrfc2gy.us-west-2.rds.amazonaws.com:5432'
alias cdana='ssh demo.analytics.0'
alias cpana='ssh production.analytics.0'
alias cbana='ssh biomarin.analytics.0'

connect_pql() {
    psql -w -h localhost -p ${1} -U ${2} ${3}
}
alias dpql='connect_pql $MAIN_PG_PORT_DEMO rails docurated'
alias ppql='connect_pql $MAIN_PG_PORT_PROD rails docurated'
alias bpql='connect_pql $MAIN_PG_PORT_BIO rails docurated'

alias dpqlact='connect_pql $ACT_PG_PORT_DEMO activitydemo activity'
alias ppqlact='connect_pql $ACT_PG_PORT_PROD activityproduction activity'
alias bpqlact='connect_pql $ACT_PG_PORT_BIO activitybiomarin activity'

alias dpqlana='connect_pql $ANA_PG_PORT_DEMO analyticsdemo analytics'
alias ppqlana='connect_pql $ANA_PG_PORT_PROD analyticsproduction analytics'
alias bpqlana='connect_pql $ANA_PG_PORT_BIO analyticsbiomarin analytics'

alias dpqlair='connect_pql $AIR_PG_PORT_DEMO airflowdemo airflow'
alias ppqlair='connect_pql $AIR_PG_PORT_PROD airflowproduction airflow'

alias dcql='cdcass 0 && cqlsh'
alias pcql='cqlsh production.cassandra.0'

alias cadmin='sshconnect production admin'
alias cchef='docutil && $DOC_HOME/utilities/docformation/docconnection.rb chef.workstation'
# postgres
alias pql='psql -d docurated -p 5432'

# reset the stupid mac osx DNS for tunnelblick to work
alias resetdns='sudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.mDNSResponder.plist && sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.mDNSResponder.plist'

# ===== CLIENT APP ========
setDemoVersion() {
    cd $DOC_HOME/clients/deploy
    rm client_demo_version.txt
    touch client_demo_version.txt
    echo $1 > client_demo_version.txt
    s3cmd put client_demo_version.txt s3://docurated-private/client_demo_version.txt
}

alias pd='doccli && python docurated.py'
alias pyserv='doccli && python -m SimpleHTTPServer'
alias coffserv='doccli && cd browser && coffee --watch --compile --output lib/ src/'
# alias cliserv='doccli && pyserv'
# alias cliserv='doccli && cd browser && coffserv'
alias clogd='doccli && tail -f app.log'
alias clog='tail -f ~/.docurated/app.log'
alias mount_vol='sudo mount -t smbfs //Guest@50.17.45.211/vol /private/nfs'
alias msd='sudo mount -t smbfs //Guest@50.17.45.211/vol /private/nfs'


# ===== RAILS ========
alias rs='rails s'
alias rc='rails c'
alias rsp='rails s -p '
alias rcd='docweb && rails c development'
alias rsd='docweb && thin start --ssl --ssl-verify --ssl-key-file ~/Development/server.key --ssl-cert-file ~/Development/server.crt'
alias wlog='docweb && tail -f log/development.log'


# ===== SOLR ========
alias solr_start='/usr/local/opt/solr/bin/solr start -c'
alias solr_stop='/usr/local/opt/solr/bin/solr stop -all'
alias testsolrs='docweb && bundle exec sunspot-solr start -p 8984'
alias testsolrr='docweb && bundle exec sunspot-solr run -p 8984'


# ===== SERVICES ========
alias serv_topo="cd $DOC_HOME/services/javaworker && sbt topology/run"
alias serv_master="cd $DOC_HOME/services/javaworker && sbt master/run"


# ===== WORKERS ========
alias resqd='open https://demosecure.docurated.com/site/resque/overview'
alias resqp='open https://admin.docurated.com/site/resque/overview'

alias start_resqs='docweb && resque-scheduler --environment development &'
alias start_resqp='docweb && resque-pool --environment development &'
alias start_sidekiq='docweb && RAILS_ENV=development sh bin/sidekiq.sh start &'

alias stop_resqs='pkill -f "resque-scheduler"'
alias stop_resqp='pkill -f "resque-pool-master"'
alias stop_sidekiq='docweb && RAILS_ENV=development sh bin/sidekiq.sh stop'

alias start_workers='start_resqs; start_resqp; start_sidekiq'
alias stop_workers='stop_resqs; stop_resqp; stop_sidekiq'

alias start_dynamo='cd ~/dynamo && nohup java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -inMemory -port 8888 > ~/dynamoout.txt 2> ~/dynamoerr.text < /dev/null &'

alias start_all='pstarts; testsolrs; start_dynamo; solrs &'
alias start_cli='pyserv &; coffserv &; doccli; mount_vol'

alias dresq='docutil && docformation/docconnection.rb demo.railsapp "ps -ef f | grep resque"'
alias sresq='docutil && docformation/docconnection.rb stage.railsapp "ps -ef f | grep resque"'


